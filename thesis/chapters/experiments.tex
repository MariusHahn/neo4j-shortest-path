\chapter{Experiments}

In this chapter we will experimentally test if our idea and implementation of a persisted version of CCH is working.
We answer answer the following questions:
\begin{itemize}
    \item What is the largest graph we are able to index?
    \item Are we able to beat dijkstra's performance? If yes, by how much?
    \item Is there a category of queries which works better than others?
    \item Do different buffer sizes change the performance significantly?
    \item Is the input graph size the only factor that affects the performance?
    \item How long do updates take if we change all arc weights?
    \item Do updates affect the performance of the search?
\end{itemize}

\section{The Test Environment}

We implemented this CCH in \textit{Java 17} and for \textit{Neo4j 5.1.0}.
The only addition Java library we use is \textit{lombok version 1.18.24} for static code generation like getter and setters.
\\
The code is deployed on a virtual machine which runs \textit{Linux Mint 20.3 Una}.
This VM has two  AMD EPYC 7351 16-Core Processors with L1d cache=1 MiB L1i cache=2 MB, L2 cache=16 MB and L3 cache=128 MB.
It has 512 GB of RAM and the system hard drive is an \textit{Intel SSDPEKNW020T8} SSD with 2 TB.
The fact that our test environment uses a SDD hard drive is not ideal.
Databases usually use HDD drives which are slower in reading data but faster in writing data.
However, our biggest index has 430MB in total, depending on the caching size and algorithm the disk uses, it would be possible that 
the HDD would pre cache the whole index, such that there are few actual reads to the disks in the HDD and the read performance gets closer to what a SSD can achieve.

\section{The Test Data}

The test graphs we evaluate for the implementation are provided by the 9th DIMACS Implementation Challenge - Shortest Paths \cite{DIMACS}; we focus on the road networks of New York, Colorado, Florida, California+Nevada and also larger networks that represent the Great Lakes on the North American continent as well as the USA's east cost.
We use the distance graphs, only in the case of New York we tried the distance and the time travel graph.
As the results were similar and the contraction strategy does not depend on the arc weight we omitted the further tests with the time travel graphs.

\section{Test Results}

The Table \ref{tab:overview_table} depicts our basic test results.
The arc size differs from the DIMACS Challenge as we have filtered out duplicate edges.

\input{assets/tables/experimentKeyTable.tex}

We do $10,000$ point to point shortest path queries.
We never start from the same vertex the and never query the same target vertex the previous search did.
This is because starting from the same vertex or querying the same target results in the probably that at least on of the buffers already has the desired arcs in cache.
%If you always start from the same vertex or query the same target, at least one of the buffers has most probably already the right edges in cache.
This is desirable but does not reflect real world scenario.
In case you always start from the same query, dijkstra will always be a good choice, as a \textit{one-to-all} dijkstra can calculate all shortest paths from a start vertex to all reachable nodes in about 10 seconds on the Florida graph.
This cannot be beaten by CCH as it can only do one to one queries.
Though there is a \textit{one-to-all} search algorithm relying on Contraction Hierarchies, called PHAST \cite{delling2013phast}. 

\section{The Contraction}

In Table \ref{tab:overview_table} you can see the basic results of the networks we tested.
One would think that the contraction time goes along with the size of the network, but it does not.
The New York graph has has about the same contraction time as Florida which is about three times as big.
Additionally the amount of shortcuts inserted relative to the already existing arcs is almost twice as big.
This probably happens because the New York graph is much denser than the other graphs under test like, eg. Florida.
In New York, regardless of whether you take the whole state or only the city itself, there are four natural separators: \textit{Manhattan and Brooklyn}, \textit{Manhattan and Queens}, \textit{Manhattan and Bronx}, \textit{Bronx and Queens}, \textit{Staten Island and Brooklyn} as well as \textit{Staten Island and Manhattan to the mainland}.
\\ 
In contrast to New York, the population of Florida is more sparse and located on a line at the cost of both side, as well as their streets.
Therefore as shown in Figure \ref{fig:linear_contraction} the contraction can easily find vertices as separators.

\subsection{Limits} \label{sec:contraction_limits}

We decided to set the time limit a contraction should not exceed to approximately one day.
If, within this time the contraction did not finish, we decided to abort the process.
This happened for the graph \textit{Western USA}, therefore we did not try larger ones.
If one would want to calculate this size or bigger we suggest, to achieve the vertex ordering by recursive finding balanced separators as described in Customization Contraction Hierarchies \cite{CCH}.
\\
Contraction methods which rely on measures like edge difference suffer from very bad performance, if the graph becomes dense.
At the same time, the remaining graph will become more dense towards the end of the contraction process.
It is possible  that the last few nodes form a complete graph.
The graph that \textit{Great Lake} was complete with $1078$ nodes left in the queue.
At this time it toke about 110 second to contract a single vertex.
The reason is, the algorithm \ref{alg:contraction} for the contraction as proposed in this paper will always update the importance of its neighbors after each contracted vertex and re-push it to the queue $Q$ of the remaining vertices.
Updating the neighbor importance means to simulate the contraction of this neighbor.
Thus we test for all pairs of incoming and outgoing neighbors $N_\downarrow(v) \times N_\uparrow(v) \setminus N_\downarrow(v) = N_\uparrow(v)$ whether we have to insert a shortcut.
This you have to do for each element in the queue $|Q|$.
In case of a complete graph the in- and the outgoing neighbor set will have size $|Q|$.
Which lead to the this many neighbor checks $(|Q| * |Q| - |Q|)*|Q|$ which is almost $(|Q|)^3$ calls to the \textit{getContraction()} method in Algorithm \ref{alg:contraction}, to checks whether to insert a shortcut or not.
In case the graph reaches completion on the last 100 this is a doable exercise.
However, in case there are 3000 remaining, it will starve.
\\
Our test show that as if the number of neighbors that are not contracted yet rise above $150$, it takes 500+ milliseconds to contract a single vertex.

\section{Query Performance}

In this section we look into the query performance.
The query performance depends mainly on the quality of the contraction and the buffer size.
As the circular buffer we implemented performs better we will focus on this one.
\\ 
One of the big questions can we even beat dijkstra's performance.
As visible in Table \ref{tab:overview_table}, our CCH algorithm was faster on average.
For all graphs under test the query times improved significantly in comparison to dijkstra.
Especially for the graph which represents Florida the query performance improvement was tremendous.
It was possible to reduce an average query time from 2.6 seconds to 0.039 seconds when having the whole graph in memory.
But even if we only have 640kB in cache, the query performance did improve by factor five to sixteen.
Increasing the cache to 20\% of the edge size the graph has sometimes lead to better results, for example in California+Nevada.
Here we could decrease the query time by half.
For some other graphs it did not entail any improvement as for Colorado.
The other graphs had some improvement, in the region of around 20\%.
A 20\% caching strategy could be useful if you have an application which often queries the same vertex.
With $t^{40kB}_{cch}$ and $t^{40kB}_{cch-updated}$ we also tested the performance after updates have happened.
It showed very little change in that.
All queries got slightly worse but did not loose much.

\subsection{Short and Long Distance Queries}

Figure \ref{fig:dijkstra_vs_cch_query_speed} shows the speed difference of Dijkstra and CCH-shortest path query.
As one can see, the bigger distance, the greater the advantage of CCH over dijkstra.
Small queries where the shortest path involve only a few hundred vertices show little improvement in speed, whereas long distance queries are a lot faster.
Figure \ref{fig:dijkstra_vs_cch_query_speed} is a random sample of queries in California and Nevada.
As visible in the left chart, there are some long distance queries for which dijkstra performs very good, although you cannot see them in the right chart, which has the path length on its x-axis.
We assume the good performing long distance queries to be in Nevada as its road network is sparser compared to those of California.
Therefore we added the right chart.
It shows the advantage of CCH over dijkstra depends on the path length of the shortest path.
This is underlining our theory as there are still some longer well performing queries but now they are closer together.

\input{assets/plots/dijkstra-vs-cch-query-speed.tex}

\subsection{Query Analyses}

Figure \ref{fig:dijkstra_vs_cch_expanded_vertices} we compare the amount of vertices the search query has to expand to find the shortest path.
As expected Dijkstra's algorithm expands roughly quadratic many vertices to find the shortest path between vertices for shortest paths that involve up to 1000 vertices.
After that the search touches the network borders and starts to expand the last leaves which happens almost linear.\\
The CCH search only expands vertices of higher rank.
As you can see in Figure \ref{fig:dijkstra_vs_cch_expanded_vertices} the CCH expands at most around 1600 vertices.
Therefore, we assume, CCH needs at most expand 800 vertices per search side to find the node with the highest rank.
Thus no matter which source or target one chooses, the query will be bound to these 1600 vertex expansions.
This is the reason CCH performs so well especially for long distance queries.
\\
So far we have only looked at long distance queries.
Now, we will have a look at the short ones, but queries where source and target are more that 300 vertices apart already perform as good as or better compared to Dijkstra's algorithm.
The search sides of these queries are even shorter than 800 expanded vertices.
They can find the shortest path within a few hundred node expansions.

\input{assets/plots/dijkstra-vs-cch-expanded-vertices.tex}

\section{IO's at Query Time}

\begin{wrapfigure}{r}{0.58\textwidth}    
    \input{assets/plots/io-comparison}
    \caption{I/O's over Expanded Vertices for 40kB cache size per search side.}
    \label{fig:io_comparison}
\end{wrapfigure}

we did our implementation to show that CCH could also fit for a graph database it is essential to have a look into how many I/O's are cased by our search.
As stated in section \ref{sec:how_to_store}, the arcs of one vertex are always stored in a single disk block.
Therefore the worst case scenario is that there is one I/O per expanded vertex.
In Figure \ref{fig:io_comparison} we can do better.
With a cache size of only 640 kB which gives the possibility to hold 40960 arcs in cache we already achieve around 1.4 expanded vertices per I/O.
This means in a bit less than every second we accidentally had the right set of arc in memory, when a new vertex was requested.
This is pretty impressive as 81920 arcs are about 0.6\%  of the arcs the road network of California and Nevada contains after the contraction.


For bigger networks like the \textit{Great Lakes} and \textit{Eastern USA} this cache size was too small.
In most scenarios we had about as many I/O's as  expanded nodes.
Thus we will have to increase in size.

\section{Circular Buffer}

\begin{figure}[H]
    \input{assets/plots/coloradoBufferComp.tex}
    \caption{Comparison of CCH query I/O's. One query was done with 640kB buffer size, the other with 20\% of all arcs}
    \label{fig:coloradoBufferComp}
\end{figure}

Here we want to compare the I/O's a query needs to find the shortest path.
From the Table \ref{tab:overview_table}  it is visible that on average I/O's decreases heavily.
In Figure \ref{fig:io_comparison} you can see the I/O's over the dijkstra path length.
It becomes clear that the increase of the buffer size lead to a reduction of I/O's for almost all queries.
Interesting to see is also the increased buffer size also lead to lower the upper bound of I/O's a query needs to finish.
This is a very useful observation, it is easily possible to figure out how many I/O's you can afford and choose the buffer size respectively.


\section{Updates and I/O's}

In Table \ref{tab:overview_table} $ I/O^{640kB}$ and $I/O^{40kB}_{cch-upd.}$  present how many I/O's a query needed on average, before and after.
As you can see the number of I/O's roughly doubled for all of them. However after multiple updates it did not get worse, than that. 


