\chapter{Integration into Neo4j}

In this section it is described how Customization Contraction Hierarchies \cite{CCH} is integrated into Neo4j.
CCH augments the input graph, which means it inserts arcs, so called shortcuts, which do not belong to the original data.
We want to keep the change to the input graphs as small as possible.
We decided not to insert any arc into the graph which is stored inside the Neo4j database, but introduce another graph data structure, the index graph.
%Through that decision we get full control over the data structure so we can decide how to store it.
The mapping between the index and the input graph, which resides in the database, is achieved by the rank property.
The rank property is set to the input and the the index graph at contraction time.
Through this we achieve a unique mapping between $G$ and $G'$.
This results in another two advantages.
Firstly, we gain full control of the graph representation which is helpful to efficiently store and read the index graph for the disk.
Secondly, it makes it easier to later on port the idea to another graph database manufacture.
Additionally we should mention here that the plugin documentation Neo4j provides is incomplete. 
The only solution is to reverse engineer their code as it always stops where things become interesting. 
Presumably a support marketing strategy. 

\section{Index Graph Data Structure}\label{sec:index_graph}

\begin{figure}
    \input{assets/uml/vertex.tex} 
    \input{assets/uml/arc.tex}
    \caption{Index Graph}
    \label{uml:index_graph}
\end{figure}

The index graph data structure is neither an adjacency list nor an adjacency matrix.
There is a vertex object which has two hash tables.
One for incoming arcs and one for outgoing arcs.
The hash tables key is of type \textit{Vertex} and the value is of type \textit{Arc}.
An arc has a reference to its start vertex and one to its end vertex as shown in Figure \ref{uml:index_graph}.
This also means we cannot construct them all at once, but need a function which initializes the graph because we have a circular reference.
If you want to initialize such a graph, for an ID pair that represents an arc or from a relationship that come from Neo4j, our solution:
We iterate over all ID pairs, create all vertices which we have not seen so far an push them to a hash table.
Then we create the arc and attach the vertices to it.
We receive the vertices from the hash table.
Finally we add the arc to its start and end vertex.
\\
A disadvantage of this model could be that some modern hardware optimization that exist for arrays do not match with this data structure.
Due to paging algorithms as described in "Modern Operating Systems" \cite{andrew2015modern} the values of an array are stored sequentially in main memory.
When one value of an array is accessed by the CPU, modern hardware reads subsequent values into the CPU-cache because they most probably reside inside the same main me page.
The model of the index graph is a linked data structure, a bit like a linked list.
The elements of a linked list are contained somewhere in main memory.
There is no guarantee that subsequent values have any spacial proximity.
However, this makes the the graph traversal easy.
Additionally it makes it very efficient to explore the neighborhood of a vertex.
There is no array traversal to find a vertex and only one hash table lookup for finding an arc of a vertex.
On a small graph, which represents the road network of Oldenburg, shows that CCH queries can be answered in less than one millisecond, which is close to our test results with the original CCH application.

\section{The Mapping}\label{sec:mapping}
\begin{figure}
    \centering
    \input{assets/tikz/neoToDiskMapping.tex}
    \caption{Mapping between Neo4j and the index graph}
    \label{fig:mapping}
\end{figure}

The in-memory data structure of Neo4j is similar to the explained index graph data structure in section \ref{sec:index_graph}.
A \textit{node} has a collection of \textit{relationships} and a \textit{relationship} has a reference to its \textit{start node} and \textit{end node}.
As Neo4j is a full blown property graph, nodes and relationships contain a lot of other information.
A node has a collection of \textit{labels}, a relationship has a \textit{type}.
The class \textit{Node} and the class \textit{Relationship} 
are both derived from the class \textit{Entity} which also has a collection of properties as well as an ID that is managed by the database system.
Note that, as of version Neo4j 5.X, this ID can change over time and should not be used to make mappings to external systems.
Additionally worth mentioning here is that the Neo4j system shifted its ID concept as it moved from major release 4 to 5.
Until major release 4 every entity had a unique integer identifier.
Since major release 5 every entity has a string identifier which is a UUID and the old \textit{id} identifier is not guaranteed to be unique anymore.
It is deprecated and marked for removal.
\\
As just explained there is lot of information in this data structure.
A lot of information we do not need.
Looking at Figure \ref{fig:mapping} we only want to keep track of the information which is needed for the CCH index.
Additionally as disks are divided  into blocks and sectors we want to flatten the graph, which in memory more looks like a tree, to a structure that looks like a table.
Therefore we decided that the disk data structure only consists of arcs $\bigcirc A$.
A DiskArc $a \epsilon \bigcirc A$ consists of four values, 
the \textit{start rank}, the \textit{end rank}, the \textit{start rank} and the \textit{weight}.
The middle node is set $-1$ in case that this arc is an arc of the input graph.
We will get two arc sets $\bigcirc A_\downarrow$ for the downwards graph and $\bigcirc A_\uparrow $ for the upwards graph.
$\bigcirc A_\downarrow$ contains all downward arc which are needed for the backward search and $\bigcirc A_\uparrow$ contains all upward arcs that are needed for the forward search.
\\
During the contraction every node gets assigned a rank.
This rank is the only change that is made to the Neo4j data structure and it is the mapping identifier between the input graph $G$ and the index graph $G'$.
$G'$ will then be used to generate $\bigcirc A_\downarrow$ and $\bigcirc A_\uparrow$.


\section{How to Store the Index Graph}\label{sec:how_to_store}

\begin{figure}
    \centering
    \input{assets/tikz/diskBlock.tex}
\caption{Disk Block}
    \label{fig:disk_block}
\end{figure}

After generating the index graph $G'$, we now want to store it as efficiently as possible to the disk.
In order to refine the definition of a disk arc.
It consist of four $4 Byte$ signed integer values \textit{start rank}, the \textit{end rank}, the \textit{middle rank} and the \textit{weight} as you can see in Figure \ref{fig:disk_block}.
\\
These 16 Byte disk arcs are collected into disk blocks.
The size of a block can be set as parameter but has two lower bounds.
At first a disk block should not be smaller as the block size of the file system beneath as this is the smallest unit one can get and it would be a waste of space.
Therefore it should also be a multiple of the system disk block size.
The second lower bound is the maximum upwards or downarrow degree that exists in the index graph after the contraction, as all upward arcs a vertex have to be stored in the same disk block.
This applies for the downward arcs, too.

\begin{equation*}
    max(d_{\uparrow max}(v), d_{\downarrow max}(v)) \leqslant  \frac{diskBlockSize}{16}  
\end{equation*}

\subsection{Persistance Order}\label{sec:persistanceOrder}

\input{assets/pseudocode/storeFunction.tex}

As the disk arcs are used for the CCH search, we want to sequentially write them in a way which provides a high spatial proximity of vertices that are likely to be requested together.
Here we will adopt the idea of Mobile Route Planning \cite{Sanders}.
In the transformation form $G'$ to its disk arcs $\bigcirc A_\uparrow$ and $\bigcirc A_\downarrow$ we conduct a simple depth first search on all ingoing arcs on the target rank to determine the order for $\bigcirc A_\uparrow$.
We provided the algorithm for that in Algorithm \ref{alg:store_dfs}.
As you can see in Figure \ref{fig:store_function}, the \textit{StoreFunction} receives the vertex with the highest rank, whether it shell store the upward or the downwards graph and the path, where to store the arcs onto the disk.
For the upwards graph the mode is set to upwards.
At initialization we push an iterator over all incoming vertices that reach the top vertex to stack.
Also we open a file writer for writing the arc and one file writer for writing the position file as shown in Figure \ref{fig:position_file}.
Then we start the \textit{store()} function of Algorithm \ref{alg:store_dfs}.
As long as the stack is not empty we pick the top iterator of the stack, but leave it inside.
Afterwards we check if that iterator still holds a vertex.
If not we remove the iterator and continue.
If it holds one we retrieve it.
If that vertex has not yet been written to the disk, we tell the arc writer to store it.
The arc writer will return the disk block number at which the arcs of that vertex are stored in the arc file.
This position writer will keep track of this information.
Then we call the \textit{neighbors()} function which returns an iterator of this vertex's neighbor sorted ascending by their rank.
Finally when the algorithm stops, we write the position file onto the disk and flush the rest of the arc file buffer.
\\
We do the same for all the downwards graph using all outgoing instead of the incoming arcs to determine the neighborhood.
The arc writer is a write buffer that is as big as the defined disk block size.
If during an iteration step there have been more arcs pushed to this arc writer than would fit in the current block, the arc writer flushes its cache to the disk, filling the remaining disk arc slots with four times $-1$.

\begin{figure}
    \centering
    \input{assets/tikz/positionFile.tex}
    \caption{Position File}
    \label{fig:position_file}
\end{figure}

\begin{figure}
    \centering
    \input{assets/uml/storeFunction.tex}
    \caption{Class Diagram of the StoreFunction}
    \label{fig:store_function}
\end{figure}

\section{Reading Disk Arcs}

If one wants to get all upward arcs of rank $i$ one needs to take  the upwards position file, retrieve the integer $j$ which is stored at index $i$, and read the complete block $j$ in the upwards arc file.
One will get an array, containing the requested arcs but also some others.
These arcs are likely to be requested next.
Therefore we want to keep them in main memory and to do so we use buffers. 
We implemented two buffers a \textit{circular buffer} and a \textit{least recently used buffer} LRU.

\subsection{Circular Buffer}

We implemented a circular buffer to read and cache the DiskArcs at query time.
One might also call it FiFo-buffer, which is correct too. 
The key properties of this buffer are:

\begin{itemize}
    \item The element that resides inside the longest will be overwritten next if a new element is fetched from the disk. So \textit{first in first out} or FiFo.
    \item If the maximum number of elements the buffer is reached it starts to overwrite the elements from the beginning. Therefore \textit{circular} or \textit{ring} buffer.
    \item A element is never \textit{take out}. This means, elements that have been requested and returned will stay inside the buffer until they will be eventually overwritten. 
\end{itemize}
Figure \ref{fig:circular} is simple visualization, for a circular buffer of upward arcs.
There is the DiskArc array that has already been filled with some arcs, a position hash table that contains the last index at which one will find an arc for the requested rank and a write pointer, which points at the position we have to continue writing when the next cache miss occurs.

\begin{figure}[H]
    \centering
    \input{assets/tikz/CircularBuffer.tex}
    \caption{Circular Buffer for upward arcs}
    \label{fig:circular}
\end{figure}

If a rank is requested which is already in the buffer, we check its position in the positions hash table and start iterating with decreasing index from the retrieved position until the start vertex of the arc we read has a different rank than the one requested.
If we reach the start of the DiskArc query the iteration index is reset to the last index of the DiskArc array, such that we continue reading at the end of the DiskArc array.
\\
If the rank we requested is not in the hash table we request the containing block from the disk.
We receive an array of DiskArcs which contains all arcs of the requested rank and maybe some more, which are also likely to be requested soon.
At first we insert $-1$ for the request rank into the hash table.
This is because one will not find a DiskArc for each rank.
For instance the vertex with the highest rank will not have any outgoing arcs.
To prevent having such vertices requested from the disk every time the search touches the top of the graph we have a $-1$ in the position table and if that rank is requested we simply return an empty collection.
We iterate the load DiskArc array.
For each DiskArc we insert the start arc rank into the position table together with the current position.
The DiskArc inserted into the array at the current position.
After each insert we increment the positionWriter by $1$.
If we reach the end of the buffer array it is set back to $0$.
\\
As it is possible that we only partly overwrite some arc sets which are already in the buffer, we receive the start rank of the arc at the \textit{writePointer} position and remove this rank from the positions table after each disk read invocation.
\\ 
Determining whether a arc set is inside the buffer is not trivial.
If it is not in position table, it is not in the buffer.
If it is in the positions table it is possible that it has been overwritten.
Thus we check whether at position we retrieve from the table there is actually a arc that starts with the requested rank.
If yes, the buffer contains the arc set, if no it does not  and we remove that rank from the position table.

\subsection{Least Recently Used Buffer}

With the class \textit{java.util.LinkedHashMap} it is very easy to create a LRU-Buffer.
It provides the possibility to evicted the entry that has been requested the furthest in the past, if a certain key size has been reached.
In our case it maps ranks to sets of disk arcs.
We can only determine how many disk arc sets we have in memory and disk arc sets do not always have the same size.
Higher rank vertices usually have more arcs as they are of higher degree.
The advantage is, it is very easy to implement and therefore very resilient to programming errors.

\section{The Search}

The search combines everything explained in this chapter.
At the beginning we create two index graphs, the upwards graph $G_\uparrow'(V_\uparrow, A_\uparrow)$ and the downwards graph $G_\downarrow'(V_\downarrow, A_\downarrow)$.
We are looking for the shortest path from the source vertex $v(s)$ to the target vertex $v(t)$.
The vertex set $V_\uparrow$ of the upwards graph $G_\uparrow'(V, A_\uparrow)$ only contains one vertex $v(s)$ and the upward arc set is empty $A_\uparrow = \emptyset$.
\\
The vertex set $V_\downarrow$ of the downwards graph $G_\downarrow'(V_\downarrow, A_\downarrow)$ only contains the $v(t)$ and the arc set is empty $A_\downarrow = \emptyset$.
Looking at the graph in Figure \ref{fig:lazy_load_vertex} it visualizes the upwards search size after initialization.
The arcs an vertices in grey have not yet been loaded.
\\
As defined in section \ref{sec:dijkstra}, the vertices of the dijkstra query are wrapped in an object called \textit{DijkstraState} which is defined in Figure \ref{fig:dijkstra_class}.
We now extend this class by one parameter, the \textit{VertexLoader} which you can see in Figure \ref{fig:lazy_load_vertex}.
The \textit{VertexLoader} has only one method \textit{addArcs(vertex: Vertex)}.
If you pass a vertex to this method the VertexLoader will take that vertex and attach all its arcs and their end vertices to it.
This happens when the \textit{expandNext()} method in Algorithm \ref{alg:disjkstra_algorithm} calls \textit{state.settle()}.
This follows the observation that the arcs of a vertex in dijkstra are only of interest if the query is about to expand this vertex.
\\
The \textit{VertexManager} gets \textit{DiskArc}'s from a \textit{Buffer}.
The buffer can be of any buffer type it only has to implement the \textit{arcs(rank: int):Set<DiskArc>} method.
The \textit{VertexManager} is responsible create the arcs and vertices form the \textit{DiskArc}'s it gets.
A \textit{Buffer} contains some type of collection data structure caches \textit{DiskArc}'s.
When the vertex manger requests some arcs the \textit{Buffer} checks whether they have already been cached.
If yes it returns them.
If not it will request the arcs from the hard drive.
This whole process is also visualized in Figure \ref{fig:lazy_load_vertex}.
\\
After starting the CH-Dijksta as described in Algorithm \ref{alg:cchSearch} both $G_\uparrow'$ and $G_\downarrow'$ are alternatingly expanded and the vertices will be attached when needed.
This can be compared to Command \& Conquer or other real-time strategy video games where you start at a map that is almost completely grey and the map only loads to your current position plus some buffer.

\begin{figure}
    \centering
    \input{assets/tikz/lazyLoadVertex.tex}
    \caption{Lazy load vertex at query time}
    \label{fig:lazy_load_vertex}
\end{figure}


%\begin{figure}
%    \centering
%    \input{assets/tikz/CircularBuffer.tex}
%    \caption{Circular Buffer}
%    \label{fig:circular_buffer}
%\end{figure}
